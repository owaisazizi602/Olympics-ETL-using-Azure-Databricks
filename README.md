# Olympics-ETL-using-Azure-Databricks


![Screenshot 2024-12-07 at 00 04 31](https://github.com/user-attachments/assets/ac6ff4b8-d19a-4e8f-8463-995dc3c23255)





Title: Azure Data Engineering Pipeline for Tokyo Olympics Data

Description:

This project showcases an end-to-end data engineering pipeline for the Tokyo Olympics dataset sourced from Kaggle. The pipeline leverages Azure services to ingest, transform, and analyze the data effectively:


Data Ingestion: Data is ingested into Azure Data Factory from the Kaggle dataset and stored in Azure Data Lake Storage Gen2.

Data Transformation: Using Azure Databricks, the data is transformed and cleaned before being written back to the transformation layer in Data Lake Storage Gen2.

Data Analytics: The transformed data is analyzed using Azure Synapse Analytics, enabling efficient querying and insights generation.

Visualization: Analytical insights are visualized using Tableau, completing the data lifecycle.

This project demonstrates the integration of Azure services for efficient data handling and analytics, showcasing best practices in cloud-based data engineering.
